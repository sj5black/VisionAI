# VisionAI Pipeline - 모델 선택 근거

## 📊 각 단계별 모델 선택 비교

---

## Step 1-2: Object Detection + Keypoint Detection

### 요구사항
- 개/고양이 존재 감지
- 위치 파악 (Bounding Box)
- 신체 부위 키포인트 탐지

### 후보 모델

#### 1. YOLOv8n ✅ **선택됨**

| 항목 | 값 |
|------|-----|
| 크기 | 6.3 MB |
| 파라미터 | 3.2M |
| mAP@50-95 | 37.3 |
| 속도 (GPU) | 20-30ms |
| FPS | 30-50 |

**장점**:
- ✓ 매우 경량 (6.3 MB)
- ✓ 빠른 추론 속도
- ✓ Object + Pose 통합 지원
- ✓ COCO 사전 학습 (고양이/개 포함)
- ✓ 쉬운 설치 및 사용

**단점**:
- 정확도가 더 큰 모델보다 낮음

#### 2. YOLOv9t

| 항목 | 값 |
|------|-----|
| 크기 | 4.0 MB |
| mAP@50-95 | 38.3 |
| 속도 | 약간 더 빠름 |

**선택하지 않은 이유**:
- YOLOv8이 더 성숙한 생태계
- Pose estimation 지원 불확실
- 미미한 성능 차이

#### 3. YOLOv8s

| 항목 | 값 |
|------|-----|
| 크기 | 22 MB |
| mAP@50-95 | 44.9 |

**선택하지 않은 이유**:
- ✗ 3.5배 더 큼 (22 MB vs 6.3 MB)
- ✗ 느린 추론 속도
- 경량화 요구사항에 맞지 않음

#### 4. Faster R-CNN ResNet50

| 항목 | 값 |
|------|-----|
| 크기 | ~150 MB |
| mAP | ~37 |
| 속도 | ~50-100ms |

**선택하지 않은 이유**:
- ✗ 매우 heavy (150 MB)
- ✗ 느린 속도
- ✗ Two-stage detector (복잡함)

### 결론

**YOLOv8n**을 선택한 이유:
1. **경량화**: 6.3 MB로 매우 작음
2. **통합성**: Object + Pose를 하나의 프레임워크에서
3. **실용성**: 쉬운 설치, 좋은 문서화
4. **성능**: 실시간 처리 가능한 속도

---

## Step 3: Emotion & Pose Classification

### 요구사항
- 표정 분석 (relaxed, alert, fearful, aggressive, playful)
- 자세 분석 (sitting, standing, lying, running, jumping)
- 경량 모델

### 후보 모델

#### 1. MobileNetV3-Small ✅ **선택됨**

| 항목 | 값 |
|------|-----|
| 크기 | 2.5 MB |
| 파라미터 | 1.5M |
| Top-1 Acc | 67.4% (ImageNet) |
| 속도 (GPU) | 5-10ms |
| 메모리 | ~10 MB |

**장점**:
- ✓ 매우 경량 (2.5 MB)
- ✓ 빠른 추론 속도
- ✓ 모바일 최적화 (ARM NEON, GPU 가속)
- ✓ Multi-task learning 적합
- ✓ ImageNet 사전 학습

**단점**:
- Fine-tuning 필요 (동물 감정 데이터)

#### 2. Vision Transformer (ViT-Tiny)

| 항목 | 값 |
|------|-----|
| 크기 | 5.7 MB |
| 파라미터 | 5.7M |
| Top-1 Acc | 75.5% |
| 속도 | 15-30ms |

**선택하지 않은 이유**:
- ✗ 2배 더 큼 (5.7 MB vs 2.5 MB)
- ✗ 느린 속도
- ✗ Attention이 꼭 필요한 태스크는 아님
- Self-attention은 작은 이미지에 오버킬

#### 3. Swin Transformer-Tiny

| 항목 | 값 |
|------|-----|
| 크기 | 28 MB |
| 파라미터 | 28M |
| Top-1 Acc | 81.3% |
| 속도 | 30-50ms |

**선택하지 않은 이유**:
- ✗ 너무 heavy (28 MB)
- ✗ 느린 속도
- ✗ 경량화 요구사항 위배
- Window attention은 불필요

#### 4. ConvNeXt-Tiny

| 항목 | 값 |
|------|-----|
| 크기 | 28 MB |
| 파라미터 | 28M |
| Top-1 Acc | 82.1% |
| 속도 | 30-50ms |

**선택하지 않은 이유**:
- ✗ 너무 heavy (28 MB)
- ✗ 느린 속도
- 고정밀 분류가 아니라 간단한 감정/자세 인식

#### 5. EfficientNet-B0

| 항목 | 값 |
|------|-----|
| 크기 | 5.3 MB |
| 파라미터 | 5.3M |
| Top-1 Acc | 77.1% |
| 속도 | 10-20ms |

**선택하지 않은 이유**:
- MobileNetV3가 더 경량 (2.5 MB)
- 유사한 성능
- MobileNet이 모바일 배포에 더 최적화

### 결론

**MobileNetV3-Small**을 선택한 이유:
1. **최경량**: 2.5 MB (후보 중 가장 작음)
2. **빠른 속도**: 5-10ms
3. **모바일 최적화**: 실제 배포 시 유리
4. **적절한 성능**: 감정/자세 분류에 충분

---

## Step 4: Temporal Action Recognition

### 요구사항
- 시간 흐름 기반 행동 인식
- 여러 프레임 정보 통합
- 경량 모델

### 후보 모델

#### 1. 규칙 기반 + 간단한 Temporal Pooling ✅ **선택됨**

| 항목 | 값 |
|------|-----|
| 크기 | 0 MB (규칙만) |
| 메모리 | ~1 MB (버퍼) |
| 속도 | <1ms |
| 정확도 | 중 (학습 데이터 없음) |

**장점**:
- ✓ 모델 파일 없음 (0 MB)
- ✓ 매우 빠름
- ✓ 해석 가능
- ✓ 학습 데이터 불필요
- ✓ 실시간 처리

**단점**:
- 유연성 낮음
- 복잡한 패턴 인식 어려움

**구현**:
```python
# 움직임 강도 계산
motion = compute_motion_intensity(bbox_sequence)

# 규칙 기반 추론
if motion < 0.1 and pose == 'lying':
    action = 'resting'
elif motion > 0.5 and emotion == 'playful':
    action = 'playing'
```

#### 2. Temporal Transformer (선택적 구현)

| 항목 | 값 |
|------|-----|
| 크기 | ~10-20 MB |
| 속도 | 10-30ms |
| 정확도 | 고 (학습 필요) |

**선택하지 않은 이유**:
- ✗ Heavy (10-20 MB)
- ✗ 학습 데이터 필요
- ✗ 규칙 기반으로도 충분

#### 3. Video Swin Transformer

| 항목 | 값 |
|------|-----|
| 크기 | 100+ MB |
| 속도 | 100-300ms |
| 정확도 | 최고 |

**선택하지 않은 이유**:
- ✗ 너무 heavy (100+ MB)
- ✗ 매우 느림
- ✗ 경량화 요구사항 완전 위배

#### 4. SlowFast Networks

| 항목 | 값 |
|------|-----|
| 크기 | 30+ MB |
| 속도 | 50-100ms |
| 정확도 | 매우 높음 |

**선택하지 않은 이유**:
- ✗ Heavy (30 MB)
- ✗ 느림
- ✗ 두 개의 pathway 필요 (복잡함)

#### 5. I3D (Inflated 3D Conv)

| 항목 | 값 |
|------|-----|
| 크기 | 50+ MB |
| 속도 | 50-150ms |
| 정확도 | 높음 |

**선택하지 않은 이유**:
- ✗ Heavy (50 MB)
- ✗ 3D Conv 연산 비용 높음
- ✗ 느림

#### 6. 1D Conv + Pooling (선택적 구현)

| 항목 | 값 |
|------|-----|
| 크기 | 1-5 MB |
| 속도 | 5-10ms |
| 정확도 | 중상 |

**장점**:
- 경량 (1-5 MB)
- 빠름
- 학습 가능

**단점**:
- 학습 데이터 필요

### 결론

**규칙 기반**을 선택한 이유:
1. **초경량**: 모델 파일 없음 (0 MB)
2. **빠름**: <1ms
3. **실용성**: 학습 데이터 없이 동작
4. **확장성**: 나중에 학습 모델로 교체 가능

---

## Step 5: Behavior Prediction

### 요구사항
- 다음 행동 예측
- 과거 행동 패턴 학습
- 경량 모델

### 후보 모델

#### 1. 규칙 기반 State Transition ✅ **선택됨 (기본)**

| 항목 | 값 |
|------|-----|
| 크기 | 0 MB |
| 속도 | <1ms |
| 정확도 | 중 |

**장점**:
- ✓ 모델 없음 (0 MB)
- ✓ 즉시 사용 가능
- ✓ 해석 가능
- ✓ 실시간 처리

**구현**:
```python
transitions = {
    'resting': {'resting': 0.6, 'walking': 0.2},
    'playing': {'playing': 0.5, 'running': 0.2}
}
```

#### 2. LSTM ✅ **선택됨 (옵션)**

| 항목 | 값 |
|------|-----|
| 크기 | <1 MB |
| 속도 | 1-5ms |
| 정확도 | 중상 |

**장점**:
- 경량 (<1 MB)
- 시퀀스 학습 가능
- 빠름

**단점**:
- 학습 데이터 필요

**구현**:
```python
class BehaviorPredictorModel(nn.Module):
    def __init__(self):
        self.lstm = nn.LSTM(32, 64, 2)
        self.fc = nn.Linear(64, num_actions)
```

#### 3. Transformer Decoder

| 항목 | 값 |
|------|-----|
| 크기 | 5-10 MB |
| 속도 | 10-20ms |
| 정확도 | 높음 |

**선택하지 않은 이유**:
- ✗ LSTM보다 크고 느림
- ✗ 짧은 시퀀스에 불필요
- ✗ Self-attention 오버킬

#### 4. GRU

| 항목 | 값 |
|------|-----|
| 크기 | <1 MB |
| 속도 | 1-3ms |
| 정확도 | 중상 |

**LSTM 대신 선택하지 않은 이유**:
- 성능 유사
- LSTM이 더 표준적
- 미미한 차이

### 결론

**규칙 기반 + LSTM (옵션)**을 선택한 이유:
1. **실용성**: 규칙으로 즉시 사용 가능
2. **확장성**: LSTM으로 업그레이드 가능
3. **경량**: 둘 다 매우 작음 (<1 MB)

---

## 📊 전체 모델 크기 요약

| 단계 | 선택된 모델 | 크기 | 대안 (안 쓴 이유) |
|------|------------|------|-------------------|
| 1-2 | YOLOv8n | 6.3 MB | YOLOv8s (22 MB, 너무 큼) |
| 3 | MobileNetV3-Small | 2.5 MB | ViT-Tiny (5.7 MB), Swin-Tiny (28 MB) |
| 4 | 규칙 기반 | 0 MB | Video Swin (100+ MB), SlowFast (30 MB) |
| 5 | 규칙 + LSTM | <1 MB | Transformer (5-10 MB) |
| **합계** | - | **~9-10 MB** | 대안 합계: 155+ MB |

**경량화 효과**: 약 **15배 작음** (9 MB vs 155+ MB)

---

## 🎯 최종 선택 원칙

### 1. 경량화 우선
- 각 단계별 가장 작은 모델 선택
- 총 10 MB 이하 유지

### 2. 실용성 우선
- 학습 데이터 없이도 동작
- 규칙 기반 폴백

### 3. 확장성 고려
- 나중에 학습 모델로 교체 가능
- 모듈화된 설계

### 4. 성능 균형
- 정확도와 속도의 최적 균형
- 실시간 처리 가능

---

## 📈 성능 비교 (예상)

### 추론 시간 (GPU)

| 구성 | 시간 |
|------|------|
| YOLOv8n | 20-30ms |
| MobileNetV3 | 5-10ms |
| Temporal (규칙) | <1ms |
| Prediction (규칙) | <1ms |
| **전체 파이프라인** | **~30-45ms** |
| **FPS** | **~25-30** |

### vs Heavy 모델 조합

| 모델 조합 | 크기 | FPS | 정확도 |
|----------|------|-----|--------|
| **경량 (현재)** | 10 MB | 25-30 | 중상 |
| Heavy (대안) | 155 MB | 5-10 | 최고 |

**결론**: 경량 모델로 **3-6배 빠름**, 크기는 **15배 작음**

---

**최종 업데이트**: 2026-02-02
